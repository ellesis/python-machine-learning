{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "#sykey-learn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import string\n",
    "import pandas as pd\n",
    "\n",
    "import datetime\n",
    "from pandas.tseries.offsets import BDay #business day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanText(row):\n",
    "    clean = row['raw']\n",
    "    clean = clean.lower()\n",
    "\n",
    "    # remove punctuation + unwanted char\n",
    "    clean2 = ''\n",
    "    for char in clean:\n",
    "        if char in \"\\n\\t\":\n",
    "            clean2 = clean2 + ' '\n",
    "        elif char not in string.punctuation + \"’\":\n",
    "            clean2 = clean2 + char\n",
    "\n",
    "    #print(clean2)\n",
    "    \n",
    "    ps = nltk.PorterStemmer()\n",
    "    wn = nltk.WordNetLemmatizer()\n",
    "    \n",
    "    words = clean2.split(' ')\n",
    "    clean_words = []\n",
    "    # remove stopwords\n",
    "    for word in words:\n",
    "        if word not in nltk.corpus.stopwords.words('english'):\n",
    "            word = ps.stem(word)\n",
    "            word = wn.lemmatize(word)\n",
    "            clean_words.append(word)\n",
    "            \n",
    "    return ' '.join(clean_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = {\n",
    "    'raw': 'Getty Images\\n\\nImagine opening: electricity feet Instagram not to post a photo or comment on someone’s story but instead to pay for your groceries.'\n",
    "}\n",
    "cleanText(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_clean_column(df):\n",
    "    df['clean'] = df.apply(cleanText, axis=1) #apply() : one by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word vectorzie TF-idf\n",
    "# TfidfVectorizer\n",
    "\n",
    "def vectorize(df):\n",
    "    tfidf_vec = TfidfVectorizer(analyzer='word', stop_words=nltk.corpus.stopwords.words('english'))\n",
    "    data = tfidf_vec.fit_transform(df['clean'])\n",
    "   \n",
    "    df2 = pd.DataFrame(data.toarray(), columns=tfidf_vec.get_feature_names())\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = [\n",
    "    'getti imag imagin open electr foot',\n",
    "    'admiss dropbox cofoud ceo drew houston spent',\n",
    "    'instagram'\n",
    "]\n",
    "test = pd.DataFrame(articles, columns=['clean'])\n",
    "vectorize(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_price_from_date(td, df):\n",
    "    datestring = td.strftime('%Y-%m-%d')\n",
    "    print(datestring)\n",
    "    row = dfp.oc [df['Date'] == datestrin]\n",
    "    if row.shape[0]== 0:\n",
    "        return None\n",
    "    \n",
    "    return row['Adj Close'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('price_AMZN.csv')\n",
    "# datestring = '2020-05-12T19:20:41+:00:00'\n",
    "# td = datetime.datetime.fromisoformat(datestring)\n",
    "\n",
    "# find_price_from_date(td, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_price_from_date(td, dfp):\n",
    "    datestring = td.strftime('%Y-%m-%d')\n",
    "    print(datestring)\n",
    "    row = dfp.loc [dfp['Date'] == datestring]\n",
    "    \n",
    "    if row.shape[0] == 0:\n",
    "        return None\n",
    "    return row['Adj Close'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfp = pd.read_csv(\"price_AMZN.csv\")\n",
    "# td = datetime.datetime.fromisoformat(\"2020-05-06T20:17:57+:00:00\")\n",
    "# find_price_from_date(td, dfp)\n",
    "dfp = pd.read_csv(\"price_AMZN.csv\")\n",
    "td = datetime.datetime.fromisoformat(\"2020-05-06T20:17:57+00:00\")\n",
    "find_price_from_date(td, dfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_big_event(datestring, df):\n",
    "    dfp = pd.read_csv('price_AMZN.csv')\n",
    "    \n",
    "    td = datetime.datetime.fromisoformat(datestring)\n",
    "    t_price = find_price_from_date(td, dfp)\n",
    "    \n",
    "    yd = td - BDay(1)\n",
    "    y_price = find_price_from_date(yd, dfp)\n",
    "    \n",
    "    if t_price == None or y_price == None:\n",
    "        return 0\n",
    "    \n",
    "    delta = abs((t_price - y_price)/y_price)\n",
    "    \n",
    "    print(\"T:%s Y:%s => %s\", t_price, y_price, delta)\n",
    "    \n",
    "    if (delta > 0.01):\n",
    "        return 1\n",
    "    else: \n",
    "        return 0\n",
    "    \n",
    "    #iso-8601 standard - date format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test is_big_event()\n",
    "# df = pd.read_csv(\"AMZN_STEP1.csv\")\n",
    "# is_big_event(\"2020-05-11T19:20:41+00:00\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_label_column(df):\n",
    "#     for idx, row in df.iterrows():\n",
    "#         res = is_big_event(row['data'], df)\n",
    "#         print(\"%s %s %s => %s\" % (idx, row['date'], row['symbol'], res))\n",
    "#         df.loc[idx, '@@label'] = res\n",
    "def make_label_column(df):\n",
    "    for idx, row in df.iterrows():\n",
    "        res = is_big_event(row['date'], df)\n",
    "        print(\"%s %s %s => %s\" % (idx, row['date'], row['symbol'], res))\n",
    "        df.loc[idx, '@@label'] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('AMZN_STEP1.csv')\n",
    "# make_label_column(df)\n",
    "df = pd.read_csv('AMZN_STEP1.csv')\n",
    "make_label_column(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    def main():\n",
    "    df = pd.read_csv('AMZN_STEP1.csv')\n",
    "    make_clean_column(df)\n",
    "    make_label_column(df)\n",
    "    dfv = vectorize(df)\n",
    "    print(dfv.info())\n",
    "    \n",
    "    df.drop(columns=['symbol', 'raw', 'clean'], inplace=True)\n",
    "    df.rename(columns={'url': '@@url', 'date': '@@date'}, inplace=True)    \n",
    "    \n",
    "    dfm = pd.concat([df, dfv], axis=1)\n",
    "    dfm.to_csv('AMZN_STEP2.csv')\n",
    "\n",
    "    return dfm\n",
    "\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
